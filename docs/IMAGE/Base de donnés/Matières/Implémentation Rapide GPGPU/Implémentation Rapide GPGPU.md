---
Code: IRGPU
UE: Outils et Mod√©lisation
URL Moodle: https://moodle.epita.fr/course/view.php?id=4002
Status: 0 Projets/DM, 0 Examens
Moyenne: "0.728"
Professeur: Edwin CARLINET & Joseph CHAZALON
Coefficient: 1.5
Moyenne /20: "14.56"
Semestre:
  - S8
Commenc√© ?: Termin√©
Projets/DM: "1"
Moyenne pond√©r√©e: "21.84"
Notes:
  - "[[Introduction aux mod√®les de programmation parall√®le et massivement parall√®le]]"
  - "[[Introduction - Architectures GPU]]"
  - "[[Premiers pas dans le calcul GPU avec CUDA]]"
  - "[[Mod√®les de programmation massivement parall√®le - 1]]"
  - "[[Mod√®les de programmation massivement parall√®le - 2]]"
Assignments/Exams:
  - "[[QCM1 IRGPU]]"
  - "[[QCM2 IRGPU]]"
  - "[[Projet IRGPU]]"
---
## üìñ R√©sum√© et contexte
Les √©volutions en mati√®re d'architecture des processeurs tendent √† pousser vers une g√©n√©ralisation des architectures multic≈ìurs et massivement parall√®le tels que les GPUs. Dans ce contexte, la ma√Ætrise des techniques de programmation massivement parall√®le est devenue obligatoire pour tirer parti des performances de ces nouveaux syst√®mes. L'objectif de ce cours est de poser les bases n√©cessaires √† la programmation de GPUs avec CUDA et d'aborder les motifs r√©currents d'optimisation GPU illustr√©s sur des probl√®mes de traitement d'images.
## üéØ Acquis d'apprentissages vis√©s (AAVs)
√Ä l‚Äôissue de ce cours, les √©tudiants sont capables dans le cadre du d√©veloppement d'une application exploitant les capacit√©s d'une architecture massivement parall√®le de :
- Comprendre les diff√©rences fondamentales entre des architectures CPUs et GPUs et leurs implications sur la programmation
- Mettre en oeuvre des benchmarks de performance et identifier les parties critiques d'un programme en termes de performances.
- Identifier les parties massivement parall√©lisables d'un programme et leurs motifs GPU correspondant.
- D√©porter des parties critiques d'un programme sur GPU en utilisant CUDA.
- Analyser les performances d'un kernel GPU et identifier ses goulots d'√©tranglement
- Optimiser un kernel GPU en appliquant les techniques d'optimisations standard vues en cours.
## üìë Plan cours
Le cours est organis√© sur deux axes : fondements th√©oriques et applications √† la programmation.
### **Chapitre 1 : Introduction aux mod√®les de programmation parall√®le et massivement parall√®le**
Apr√®s un rapide historique de l'√©volution des cartes graphiques en tant qu'acc√©l√©rateur de calcul, l'√©tudiant verra les diff√©rents mod√®les le parall√©lisme et leur correspondance hardware. En particulier, il verra le mod√®le de programmation CUDA pour les architectures GPU NVidia.
### **Chapitre 2 : Introduction pratique √† CUDA (2h CM + 2h TP)**
Apr√®s la vision formelle du mod√®le de programmation CUDA, l'√©tudiant aura une formation pratique √† CUDA au cours de laquelle il verra comment lancer des kernels pour parall√©liser des calculs simples sur des donn√©es 1D et 2D.
### **Chapitre 3 : Programmation efficace des GPUs (1e partie)**
L'√©tudiant verra comment parall√©liser des motifs simples pour r√©soudre des probl√®mes r√©currents (illustr√©s par des probl√®mes de traitement d'images). Pendant cette visite, il prendra conscience des probl√®mes potentiels de performances (notamment li√©es √† la m√©moire) et comment les r√©soudre.
Il s'ensuit un TP d'application o√π l'√©tudiant doit parall√©liser le calcul d'une synth√®se d'image avec CUDA.
### **Chapitre 4 : Programmation efficace des GPUs (2e partie)**
Cette deuxi√®me partie se concentre sur les motifs de r√©ductions dont la parall√©lisation est moins triviale.
L'√©tudiant devra ensuite appliquer ces connaissances dans le cadre d'un exercice de r√©duction du TP pr√©c√©dent.
  
  
## **üèÉFormat des activit√©s**
Formats des activit√©s p√©dagogiques:
- Cours magistraux: 8 heures
- Travaux pratiques: 6 heures
## **üñäÔ∏è √âvaluation des AAVs**
- 2 QCMs
- Projet
## **üî¢ Calcul de note finale**
- Contr√¥le continu (QCM): 2 points
- Projet & soutenance: 18 points
  
### Assignments
#### Projets/DMs et Examens
|Nom|Date|Status|
|---|---|---|
|[[QCM1 IRGPU]]|April 9, 2025|Finis|
|[[QCM2 IRGPU]]|April 27, 2025|Finis|
|[[Projet IRGPU]]|June 19, 2025|Finis|
  
  
  
### Notes
#### Notes
|Nom|
|---|
|[[Introduction - Architectures GPU]]|
|[[Introduction aux mod√®les de programmation parall√®le et massivement parall√®le]]|
|[[Mod√®les de programmation massivement parall√®le - 1]]|
|[[Mod√®les de programmation massivement parall√®le - 2]]|
|[[Premiers pas dans le calcul GPU avec CUDA]]|
  
  
  
### Exams