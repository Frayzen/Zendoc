---
MatiÃ¨re:
  - "[[Introduction aux RÃ©seaux de Neuronnes]]"
Type: Cours
Date du cours: 2025-03-20
Supports:
  - "[[intro_nn.pdf]]"
---
# [Un neurone](https://www.ricou.eu.org/iren/notes_rn.html#Neurones)
  
![[image 93.png|image 93.png]]
![[image 1 26.png|image 1 26.png]]
On a quelque chose de linÃ©aire â†’ On va donc appliquer une fonction $f$ pour enlever la linÃ©aritÃ©.
  
## Les maths
  
- $z=b+\sum_iw_ix_i$
- $y=\sigma(z)$ avec:
    - les $i$ entrÃ©e $x_i$
    - $b$ le biais
    - $w_i$ les poids
    - $\sigma$ la fonction dâ€™activation
### Fonction dâ€™activation
![[image 2 26.png|image 2 26.png]]
  
## ThÃ©orÃ¨me dâ€™approximation
  
Soit une fonction dâ€™activation $ğœ âˆˆ \mathscr{C}(â„)$ avec $ğœ$ non polynomiale, alors lâ€™espace gÃ©nÃ©rÃ© par une couche de neurones :
$\mathcal{M}_r(\sigma)=\Big\{ \sum_{i=1}^{r}c_i\sigma(w^i.x+b_i),W^i\in\mathbb{R}^d,c_i\text{ et }b_i\in\mathbb{R} \Big\}$
est dense dans $\mathscr{C}(\mathbb{R})$ au sens de la convergence uniforme sur tout $c$ c.a.d
  
## Un premier rÃ©seau neuronal
  
![[image 3 23.png|image 3 23.png]]
### Ã‰valuer les couples dâ€™entrÃ©e $(1,1), (0,1), (1,0)$ et $(0,0)$ avec $Ïƒ$ une logistique
On fais i x coef de la fleche puis on aditionne les fleches, puis on aditionne avec la fleche du haut, si > 0 alors on a 1.
  
  
# Construction dâ€™un rÃ©seau neuronal
  
Pour construire un rÃ©seau neuronal par apprentissage supervisÃ© il faut :
un grand jeu de donnÃ©es Ã©tiquetÃ©es par la sortie voulue
- dÃ©finir lâ€™architecture du rÃ©seau avec
    - le nombre de couches
    - les types de couches
    - le nombre de nÅ“uds par couche
    - les fonctions dâ€™activations
    - les connexions inter-couches
    - toutes astuces qui fonctionnent
- une fonction dâ€™erreur pour guider la correction sur les poids
- une mÃ©thode pour faire converger le rÃ©seau (trouver les bons poids)
  

> [!important] On manque de mathÃ©matique lourdes dans ce domaine, donc il y a un aspet â€œartistiqueâ€
  

> En cas de problÃ¨me, on sacrifie un poulet.
  
## Les donnÃ©es
  
Les donnÃ©es doivent Ãªtre
- trÃ¨s nombreuses (assez pour dÃ©finir toutes les inconnues du rÃ©seau)
- de bonne qualitÃ© (pour ne pas tromper le rÃ©seau)
On appronfondira avec des exemples et lâ€™utilisation de Pandas pour nettoyer les donnÃ©es.
![[image 4 22.png|image 4 22.png]]
  
Si on trie les Ã©tiquettes au hasard on auras 0,5.
  
## Lâ€™architecture du rÃ©seau
  
Câ€™est la partie tactique et artistique.

> [!important] Lâ€™Ã©tude des diffÃ©rents rÃ©seaux nâ€™entre pas dans le cadre de ce cours dâ€™introduction.
![[image 5 21.png|image 5 21.png]]
  
# [Fonction dâ€™erreur](https://www.ricou.eu.org/iren/notes_rn.html#Fonction%20d%27erreur)
  
La fonction dâ€™erreur indique de combien le rÃ©seau sâ€™est trompÃ© par rapport Ã  la vÃ©ritÃ© terrain $(ğ‘¦\text{ vs }ğ‘¡)$. Elle doit Ãªtre :
- dÃ©rivable
- correspondre au problÃ¨me traitÃ©
Cette fonction est aussi appelÃ©e fonction de coÃ»t (cost function ou loss function).
  
**Exemples**
- Lâ€™erreur quadratique $ğ¸ = (ğ‘¦ âˆ’ ğ‘¡)^2$
- $ğ¸ = log(cosh(ğ‘¦ âˆ’ ğ‘¡))$ quadratique puis linÃ©aire lorsque lâ€™Ã©cart croÃ®t
- Lâ€™entropie croisÃ©e pour des probabilitÃ©s (valeurs entre 0 et 1)
    
    $E=-\sum_kt_k\ log(y_k)+(1-t_k)\ log(1-y_k)$