---
title: Fusion de caractÃ©ristiques
MatiÃ¨re:
  - "[[Introduction au Machine Learning]]"
Type: Cours
Date du cours: 2025-04-11
Supports:
  - "[[FeaturesFusion.pdf]]"
---
# Late Fusion (DÃ©cision tardive)
## âœ… DÃ©finition
Aussi appelÃ©e **fusion de dÃ©cisions**, cette approche traite **chaque ensemble de caractÃ©ristiques sÃ©parÃ©ment** avant de combiner les rÃ©sultats des classifieurs.
## ğŸ“Œ Avantages
- SimplicitÃ© de mise en Å“uvre
- FacilitÃ© de parallÃ©lisation
- Peut accÃ©lÃ©rer lâ€™infÃ©rence via des cascades de classifieurs
## âš ï¸ InconvÃ©nients
- Moins efficace en termes de performance
- Perte dâ€™information due Ã  lâ€™absence dâ€™interaction entre les features
## ğŸ¯ MÃ©thodes courantes :
### **Vote majoritaire**
consensus, moyenne pondÃ©rÃ©e
![[image 96.png|image 96.png]]
  
### **Cascade de classifieurs**
(ex. : Haar cascade)
![[image 1 28.png|image 1 28.png]]
---
  
# Early Fusion (Fusion prÃ©coce)
## DÃ©finition
Aussi appelÃ©e **fusion de donnÃ©es**, cette approche combine les caractÃ©ristiques **avant** toute classification, crÃ©ant une **reprÃ©sentation unifiÃ©e**.
![[image 2 28.png|image 2 28.png]]
## Contraintes :
- Conversion vers un **espace commun**
- **Normalisation** des donnÃ©es
- **AgrÃ©gation** cohÃ©rente des features
---
## Ã‰tapes dâ€™une early fusion :
### 1. Conversion
Uniformiser les types :
- `int â†’ float32`
- `qualitatif â†’ quantitatif` (via encodage, par ex. One-hot)
### 2. Normalisation
|MÃ©thode|Avantages|Formule|
|---|---|---|
|**Min-Max**|Simple, intuitif|$Xiâ€²=Xiâˆ’minâ¡(X)maxâ¡(X)âˆ’minâ¡(X)X'_i = \frac{X_i - \min(X)}{\max(X) - \min(X)}$|
|**Z-score**|TrÃ¨s courant, statistique classique|$Xiâ€²=Xiâˆ’Î¼ÏƒX'_i = \frac{X_i - \mu}{\sigma}$|
|**Tanh-estimator**|Robuste, efficace|$Xiâ€²=12(tanhâ¡(0.01â‹…Xiâˆ’Î¼Ïƒ)+1)X'_i = \frac{1}{2} \left( \tanh(0.01 \cdot \frac{X_i - \mu}{\sigma}) + 1 \right)$|
|**MAD (Median Absolute Deviation)**|Insensible aux outliers|$( X'_i = \frac{X_i - \text{median}(X)}{\text{median}})$|
### 3. AgrÃ©gation
- **ConcatÃ©nation** (fusion brute des vecteurs)
- **Moyenne**, **mÃ©diane**
- **Min/Max pooling**
- ... et autres mÃ©thodes statistiques
---
  
# Implicit Fusion (Fusion implicite)
## DÃ©finition
Contrairement Ã  la **fusion explicite** (early fusion manuelle), ici la fusion des caractÃ©ristiques est **apprise automatiquement par le modÃ¨le**.
## ğŸ’¡ Points clÃ©s :
- Lâ€™implicite fusion fait toujours partie dâ€™un **early fusion**, mais elle **dÃ©lÃ¨gue la tÃ¢che de fusion au modÃ¨le** (souvent complexe).
- Cela dÃ©pend fortement du classifieur utilisÃ©.
|Type de modÃ¨le|CapacitÃ© de fusion implicite|
|---|---|
|**Linear Models / RÃ©seaux de neurones**|Besoin dâ€™une fusion explicite prÃ©alable|
|**Arbres de dÃ©cision, Random Forest, etc.**|Peuvent exploiter directement des features hÃ©tÃ©rogÃ¨nes (qualitatifs + quantitatifs)|
---
  
# ğŸ“Œ RÃ©sumÃ© comparatif
|MÃ©thode|SimplicitÃ©|Performance|Besoin de prÃ©-traitement|Exemple|
|---|---|---|---|---|
|**Late Fusion**|âœ…âœ…âœ…|âŒâŒ|Faible|Votes, Cascade|
|**Early Fusion**|âŒ|âœ…âœ…âœ…|Fort|ConcatÃ©nation + Normalisation|
|**Implicit Fusion**|âœ…/âŒ|âœ…âœ…âœ…âœ…|Variable selon modÃ¨le|RÃ©seaux, arbres|
---
## ğŸ› ï¸ Applications typiques
- Reconnaissance dâ€™objets en vision par ordinateur
- Analyse de documents multimodaux (texte + image)
- Bio-informatique (fusion de signaux hÃ©tÃ©rogÃ¨nes)
- SystÃ¨mes biomÃ©triques (visage + empreinte + voix)